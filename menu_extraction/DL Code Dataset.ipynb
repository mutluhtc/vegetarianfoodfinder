{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "YELP_API_KEY=iuOGUxONHPfHGy4m6zATyltGnwzJkbLmGeOZ_fiH_0nY7dSbcLS72YfSKnBjfh5H-T3WtwUdFLCSe_RIUORYv6ELJVQEH_JhozgaMye1-yFSFq-yFcIc9cd4VGHZaHYx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4120329305.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcity_name_caps = \"Dallas, TX\"Æ’\u001b[39m\n                                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "city_name_caps = \"Dallas, TX\"\n",
    "city_name_lower = \"dallas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxPYQBbRyzIY"
   },
   "source": [
    "I have used my API key above. Please use yours respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_04_-jHKvbma"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyVa0loWvd4u"
   },
   "outputs": [],
   "source": [
    "# load variables from .env\n",
    "load_dotenv()\n",
    "# Fetch your Yelp API key from the environment\n",
    "YELP_API_KEY = os.getenv(\"YELP_API_KEY\")\n",
    "# Check it loaded correctly (show only first 6 characters)\n",
    "print(\"API Key loaded:\", YELP_API_KEY[:6], \"....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhOcHWijvxRh"
   },
   "outputs": [],
   "source": [
    "# Step 0: Install dependencies\n",
    "#!pip install python-dotenv pandas requests\n",
    "\n",
    "# Step 1: Load API key from .env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "YELP_API_KEY = os.getenv(\"YELP_API_KEY\")\n",
    "print(\"Yelp API Key loaded:\", YELP_API_KEY[:6], \"....\")\n",
    "\n",
    "HEADERS = {\"Authorization\": f\"Bearer {YELP_API_KEY}\"}\n",
    "SEARCH_URL = \"https://api.yelp.com/v3/businesses/search\"\n",
    "DETAILS_URL = \"https://api.yelp.com/v3/businesses/{}\"\n",
    "REVIEWS_URL = \"https://api.yelp.com/v3/businesses/{}/reviews\"\n",
    "\n",
    "# Step 2: Function to fetch restaurants with offset limits # Change location appropriately\n",
    "def fetch_restaurants(location=city_name_caps, term=\"restaurants\", max_fetch=200):\n",
    "    results = []\n",
    "    limit = 50  # Yelp max per request\n",
    "    for offset in range(0, max_fetch, limit):\n",
    "        params = {\"location\": location, \"term\": term, \"limit\": limit, \"offset\": offset}\n",
    "        r = requests.get(SEARCH_URL, headers=HEADERS, params=params)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Error {r.status_code}: {r.text}\")\n",
    "            break\n",
    "        chunk = r.json().get(\"businesses\", [])\n",
    "        if not chunk:\n",
    "            break\n",
    "        results.extend(chunk)\n",
    "        print(f\"Fetched {len(results)} for term '{term}' so far...\")\n",
    "        time.sleep(0.5)\n",
    "    return results\n",
    "\n",
    "# Step 3: Categories to split queries\n",
    "categories = [\"italian\", \"mexican\", \"indian\", \"chinese\", \"thai\", \"american\", \"mediterranean\", \"vegan\", \"vegetarian\"]\n",
    "\n",
    "all_restaurants = []\n",
    "\n",
    "for cat in categories:\n",
    "    results = fetch_restaurants(term=f\"restaurants,{cat}\", max_fetch=200)\n",
    "    all_restaurants.extend(results)\n",
    "\n",
    "# Deduplicate by restaurant id\n",
    "unique_restaurants = {biz['id']: biz for biz in all_restaurants}\n",
    "restaurants = list(unique_restaurants.values())\n",
    "print(f\"Total unique restaurants fetched: {len(restaurants)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7cmdS4ewQ1U"
   },
   "outputs": [],
   "source": [
    "# Step 4: Fetch business details + reviews\n",
    "all_data = []\n",
    "sample_restaurants = restaurants\n",
    "for i, biz in enumerate(sample_restaurants):\n",
    "    biz_id = biz['id']\n",
    "\n",
    "    # Details\n",
    "    details_resp = requests.get(DETAILS_URL.format(biz_id), headers=HEADERS)\n",
    "    if details_resp.status_code != 200:\n",
    "        print(f\"Details error for {biz_id}\")\n",
    "        continue\n",
    "    details = details_resp.json()\n",
    "\n",
    "    # Try to capture website / menu links\n",
    "    website_url = details.get(\"url\", \"\")  # Yelp page\n",
    "    try:\n",
    "        website_url = details.get(\"attributes\", {}).get(\"menu_url\", website_url)  # Official menu if available\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Save combined data\n",
    "    all_data.append({\n",
    "        \"id\": biz_id,\n",
    "        \"name\": details.get(\"name\"),\n",
    "        \"rating\": details.get(\"rating\"),\n",
    "        \"review_count\": details.get(\"review_count\"),\n",
    "        \"categories\": \", \".join([c['title'] for c in details.get(\"categories\", [])]),\n",
    "        \"price\": details.get(\"price\", \"\"),\n",
    "        \"address\": \", \".join(details[\"location\"].get(\"display_address\", [])),\n",
    "        \"latitude\": details[\"coordinates\"].get(\"latitude\"),\n",
    "        \"longitude\": details[\"coordinates\"].get(\"longitude\"),\n",
    "        \"url\": details.get(\"url\"),\n",
    "        \"website_url\": website_url  # <-- NEW FIELD\n",
    "    })\n",
    "\n",
    "    if (i+1) % 50 == 0:\n",
    "        print(f\"Processed {i+1}/{len(restaurants)} restaurants\")\n",
    "    time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwZUPchvwhwJ"
   },
   "outputs": [],
   "source": [
    "# Step 5: Save to CSV\n",
    "df = pd.DataFrame(all_data)\n",
    "df[\"city\"] = city_name_caps\n",
    "df.to_csv(f\"{city_name_lower}_restaurants_full_with_websites.csv\", index=False)\n",
    "print(f\"Saved to {city_name_lower}_restaurants_full_with_websites.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sn-2dM1E2CJC"
   },
   "source": [
    "The above code will generate a dataset containing all the restaurant details for the city of San Diego. Please change the code to update the location to whatever city you are looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enYKJxN62Oxg"
   },
   "outputs": [],
   "source": [
    "#!pip install pdfplumber requests beautifulsoup4 pandas\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "import pdfplumber\n",
    "#from google.colab import drive\n",
    "\n",
    "# === Function to extract text from PDF ===\n",
    "def get_pdf_text(pdf_bytes):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file provided as bytes.\n",
    "    \"\"\"\n",
    "    full_text = []\n",
    "    try:\n",
    "        with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    full_text.append(text)\n",
    "        return \"\\n\".join(full_text) if full_text else \"ERROR: No text extracted from PDF\"\n",
    "    except Exception as e:\n",
    "        return f\"ERROR extracting PDF: {e}\"\n",
    "\n",
    "# === Function to fetch website text (HTML or PDF) ===\n",
    "def get_website_text(url):\n",
    "    \"\"\"\n",
    "    Fetches the content of a website (HTML or PDF) and returns the plain text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(url, str) or url.strip() == \"\":\n",
    "            return \"ERROR: No URL\"\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": (\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/115.0 Safari/537.36\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        print(f\"Fetching content from: {url}\")\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\").lower()\n",
    "\n",
    "        if \"application/pdf\" in content_type or url.lower().endswith(\".pdf\"):\n",
    "            print(\"ðŸ“„ Detected PDF, extracting text...\")\n",
    "            return get_pdf_text(response.content)\n",
    "        else:\n",
    "            print(\"ðŸŒ Detected HTML, extracting text...\")\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "            return text if text else \"ERROR: No text extracted from HTML\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "# === Load dataset === Upload the dataset you got from the above code to the same folder where you are running your google colab notebook.\n",
    "\n",
    "#drive.mount('/content/drive')\n",
    "df = pd.read_csv(f\"{city_name_lower}_restaurants_full_with_websites.csv\")\n",
    "\n",
    "\n",
    "# Test on first 10 rows before running everything\n",
    "df_test = df\n",
    "df_test[\"raw_text\"] = df_test[\"website_url\"].apply(get_website_text)\n",
    "\n",
    "# Save the test run\n",
    "df_test.to_csv(f\"{city_name_lower}_restaurants_test_with_rawtext.csv\", index=False)\n",
    "print(f\"âœ… Test file saved: {city_name_lower}_restaurants_test_with_rawtext.csv\")\n",
    "\n",
    "# Once verified, uncomment to run full dataset:\n",
    "# df[\"raw_text\"] = df[\"website_url\"].apply(get_website_text)\n",
    "# df.to_csv(\"san_diego_restaurants_full_with_rawtext.csv\", index=False)\n",
    "# print(\"âœ… Full dataset saved with raw_text\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j4BNIxb5UOz"
   },
   "source": [
    "The above code will generate a dataset with the raw text added as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eFWUwfZ4pSz"
   },
   "outputs": [],
   "source": [
    "# The code below is used to calculate how many entries have null/empty strings/error in extracting raw text\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "#drive.mount('/content/drive')\n",
    "df = pd.read_csv(f\"{city_name_lower}_restaurants_test_with_rawtext.csv\")\n",
    "\n",
    "# Define \"error\" conditions\n",
    "mask_error = (\n",
    "    df[\"raw_text\"].isna() |  # missing values (NaN)\n",
    "    (df[\"raw_text\"].astype(str).str.contains(\"ERROR\", case=False, na=False)) |  # text contains 'error'\n",
    "    (df[\"raw_text\"].astype(str).str.strip().isin([\"\", \"None\", \"nan\"]))  # empty, None, nan as strings\n",
    ")\n",
    "\n",
    "# Count errors\n",
    "error_count = mask_error.sum()\n",
    "\n",
    "print(f\"Number of entries with errors in raw_text: {error_count}\")\n",
    "print(f\"Total entries: {len(df)}\")\n",
    "print(f\"Percentage errors: {100 * error_count / len(df):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CV_S3QSA5pqV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMT2RX3Hfwg4rRPNdw1gN7t",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
